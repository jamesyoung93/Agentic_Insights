# Architecture Overview Slide - Documentation

## ğŸ“‹ Executive Summary

This document explains how the **Agentic Insights** system architecture slide was created, the methodology used, assumptions made, and how links were verified.

**Generated:** 2025-11-12
**Primary Entry Point:** `streamlit_app_ULTIMATE.py`
**System Type:** Autonomous Data-Driven Discovery Engine
**Constraints Met:** âœ… Max 12 nodes, âœ… Max 16 edges, âœ… â‰¤60 words visible text

---

## ğŸ¯ What This System Does

**Agentic Insights** is an autonomous scientific discovery system that:

1. **Ingests** customer transaction data (CSV files) and research literature
2. **Analyzes** data through iterative discovery cycles using statistical methods (scipy)
3. **Synthesizes** findings using optional LLM integration (OpenAI GPT-3.5/4)
4. **Maintains** context via a structured "World Model" knowledge graph
5. **Produces** publication-ready reports with rigorous statistical evidence

**One-sentence value:** Automated hypothesis generation â†’ statistical testing â†’ evidence-backed discovery synthesis.

---

## ğŸ” Methodology: How the Architecture Was Built

### Step 1: Code Tracing (Entry Point â†’ Full Call Graph)

**Starting Point:** `streamlit_app_ULTIMATE.py` (1,643 lines, primary UI)

**Traced Imports:**
- `auto_enhanced_report.AutoEnhancedReportGenerator` â†’ Report generation
- `world_model_builder.WorldModel` â†’ State management
- `agents.literature_searcher.LiteratureSearchAgent` â†’ Paper search
- `agents.data_analyst.DataAnalysisAgent` â†’ Code generation
- `config.py` â†’ API keys and settings
- `main.py` â†’ CLI alternative orchestrator

**Key Functions Identified:**
- `run_discovery_cycle()` â†’ Main orchestration loop
- `perform_statistical_analysis()` â†’ Statistical tests (scipy)
- `load_data()` â†’ CSV ingestion
- `generate_research_questions_llm()` â†’ Question generation (OpenAI)
- `synthesize_discoveries_llm()` â†’ Discovery synthesis (OpenAI)
- `generate_final_report()` â†’ Report generation

### Step 2: I/O Detection (Static Analysis)

**Inputs Discovered:**
```python
# File I/O (pandas.read_csv)
- data/customers.csv (line 131)
- data/competitor_data.csv (line 148)

# JSON I/O (json.load)
- knowledge/literature_index.json (agents/literature_searcher.py:24)
- knowledge/literature/*.txt (agents/literature_searcher.py:172)

# Config (import)
- config.py (OPENAI_API_KEY, MODEL_NAME, OUTPUT_DIR)

# APIs (openai.chat.completions.create)
- api.openai.com (agents/data_analyst.py:107, literature_searcher.py:105)
```

**Outputs Discovered:**
```python
# JSON State (json.dump)
- world_model.json (world_model_builder.py:243)
- outputs/world_model_state.json (agents/world_model.py:127)

# Text Reports (file.write)
- auto_enhanced_report.txt (auto_enhanced_report.py:23)

# Generated Code
- outputs/analyses/*.py (agents/data_analyst.py:230)
- outputs/analyses/*.json (agents/data_analyst.py:226)
```

### Step 3: Component Grouping (MECE Breakdown)

**12 Components Identified:**

1. **CSV Data** (datastore) â€” Customer/competitor data
2. **Literature Store** (datastore) â€” Research papers + index
3. **Config** (input) â€” API keys, settings
4. **Streamlit UI** (service) â€” Web orchestrator
5. **Kosmos Framework** (service) â€” CLI orchestrator
6. **Data Analyst Agent** (service) â€” Code generation & execution
7. **Literature Agent** (service) â€” Paper search & synthesis
8. **World Model** (service) â€” State management
9. **OpenAI API** (external) â€” GPT-3.5/4 for LLM features
10. **World Model JSON** (datastore) â€” Persistent state
11. **Enhanced Report** (output) â€” Publication-ready text
12. **Analysis Code** (output) â€” Generated scripts

**Swimlane Assignment:**
- **Sources:** CSV Data, Literature Store, Config
- **Processing:** Streamlit UI, Kosmos Framework
- **Agent Layer:** Data Analyst, Literature Agent, World Model
- **External:** OpenAI API
- **Storage:** World Model JSON
- **Outputs:** Enhanced Report, Analysis Code

### Step 4: Edge Verification (Link Evidence)

**15 Edges Traced (all verified in code):**

| From | To | Label | Evidence (File:Line) |
|------|----|----|---------------------|
| CSV Data | Streamlit UI | Load CSV (pandas) | streamlit_app_ULTIMATE.py:131 `pd.read_csv(path)` |
| Literature Store | Lit Agent | Read papers (JSON+txt) | literature_searcher.py:24 `json.load(index_path)` |
| Config | Streamlit UI | Load settings | streamlit_app_ULTIMATE.py:13 `from config import ...` |
| Streamlit UI | Data Analyst | Research question | streamlit_app_ULTIMATE.py:788 `analysis_result = perform_statistical_analysis(...)` |
| Streamlit UI | Lit Agent | Literature query | streamlit_app_ULTIMATE.py:814 `lit_result = search_literature_llm(...)` |
| Data Analyst | OpenAI API | Generate code (REST JSON) | data_analyst.py:107 `openai.chat.completions.create(...)` |
| Lit Agent | OpenAI API | Synthesize (REST JSON) | literature_searcher.py:105 `openai.chat.completions.create(...)` |
| Data Analyst | World Model | Store trajectory | streamlit_app_ULTIMATE.py:792 `wm.add_trajectory(...)` |
| Lit Agent | World Model | Store findings | streamlit_app_ULTIMATE.py:817 `wm.add_trajectory(...)` |
| World Model | World Model State | Save JSON | world_model_builder.py:243 `json.dump(self.to_dict(), f)` |
| Streamlit UI | World Model | Update discoveries | streamlit_app_ULTIMATE.py:870 `discovery = wm.add_discovery(...)` |
| World Model | Enhanced Report | Generate report | streamlit_app_ULTIMATE.py:1097 `generator.generate_from_cycle_data(...)` |
| Data Analyst | Analysis Artifacts | Save code/results | data_analyst.py:226 `json.dump(analysis, f)` |
| Kosmos Framework | Data Analyst | CLI orchestration | main.py:84 `self.data_analyst.analyze(...)` |
| Kosmos Framework | World Model | CLI orchestration | main.py:89 `self.world_model.add_analysis(...)` |

**Verification Method:** Each edge was traced back to specific code lines using static analysis (grep + manual code reading).

### Step 5: Constraint Validation

**Slide 1 Constraints (Hard Limits):**
- âœ… **Max 12 nodes:** Exactly 12 nodes (see component list above)
- âœ… **Max 16 edges:** 15 edges (within limit)
- âœ… **â‰¤60 words total text:** 39 words measured (title + caption + node labels)
- âœ… **Diagram-first:** No bullet points on main slide
- âœ… **16:9 format:** PowerPoint set to 13.333" Ã— 7.5"
- âœ… **Legend included:** Bottom-right with shape/line styles
- âœ… **Swimlanes:** 6 columns (Sources â†’ Processing â†’ Agents â†’ External â†’ Storage â†’ Outputs)

**Font Sizes:**
- Title: 36pt (bold, Calibri)
- Caption: 16pt (italic, Calibri)
- Node labels: 16pt (bold, Calibri)
- Legend: 14pt (Calibri)

---

## ğŸ“Š Architecture Overview

### System Flow (Left â†’ Right)

```
[Sources]         [Processing]      [Agent Layer]      [External]  [Storage]        [Outputs]
CSV Data â”€â”€â”€â”€â”€â”€â”€â”€â†’ Streamlit UI â”€â”€â”€â†’ Data Analyst â”€â”€â”€â†’ OpenAI API
Literature Store â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â†’ Lit Agent â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚                      â”‚
                                     â”œâ”€â”€â”€â†’ World Model â”€â”€â”€â”€â”€â”´â†’ World Model JSON
                                     â”‚                        â†“
                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Enhanced Report
                                                               Analysis Code
```

**Key Data Transformations:**
1. **CSV â†’ DataFrame** (pandas.read_csv)
2. **Question â†’ Code** (OpenAI GPT generates Python)
3. **Code â†’ Statistics** (scipy executes analysis)
4. **Statistics â†’ Discoveries** (LLM or direct synthesis)
5. **Discoveries â†’ Report** (AutoEnhancedReportGenerator formats)

### Statistical Methods Used

| Method | Purpose | Implementation |
|--------|---------|----------------|
| Pearson Correlation | Measure linear relationships | `scipy.stats.pearsonr(x, y)` |
| Linear Regression | Predict continuous outcomes | `scipy.stats.linregress(x, y)` |
| One-Way ANOVA | Compare groups | `scipy.stats.f_oneway(*groups)` |
| Independent t-test | Compare two groups | `scipy.stats.ttest_ind(group1, group2)` |
| Effect Sizes | Quantify practical significance | Cohen's d, Î·Â², RÂ² (custom calculations) |

---

## ğŸ§© Assumptions & Verification Status

### Verified Links (All 15 Edges)

âœ… **All edges verified in code** â€” Every arrow on the diagram corresponds to an actual function call, import, or data flow in the codebase.

**Evidence Locations:**
- CSV loading: `streamlit_app_ULTIMATE.py:131` (`pd.read_csv`)
- OpenAI API calls: `data_analyst.py:107`, `literature_searcher.py:105` (`openai.chat.completions.create`)
- World Model saves: `world_model_builder.py:243` (`json.dump`)
- Report generation: `auto_enhanced_report.py:189` (`generate_enhanced_report`)

### Inferred Links (0 Edges)

âœ… **No inferred links** â€” All connections are based on static code analysis, not assumptions.

### Assumptions Made

âš ï¸ **Deployment Environment:**
- Assumed: Local Python environment or container
- Not Found: Dockerfile, Kubernetes YAML, Terraform (no infra-as-code detected)
- Conclusion: System is designed for local/manual deployment

âš ï¸ **Scalability:**
- Assumed: Single-node processing (no distributed computing code found)
- Limitation: Handles datasets up to ~5GB (based on README claims, not verified in code)

âš ï¸ **Security:**
- Warning: API key hardcoded in `config.py` (redacted in this doc for security)
- Recommendation: Use environment variables or secrets management

---

## ğŸ—‚ï¸ Deliverables Generated

| File | Purpose | Compliance |
|------|---------|------------|
| **architecture_overview.pptx** | Main slide + appendix (if needed) | âœ… Constraint-compliant (12 nodes, 15 edges, 39 words) |
| **architecture_graph.json** | Machine-readable node/edge data | âœ… Reproducible, includes verification metadata |
| **component_index.csv** | Component catalog (paths, functions, I/O) | âœ… MECE, 13 rows (12 components + header) |
| **diagram_source.mmd** | Mermaid diagram (for documentation/web rendering) | âœ… Valid Mermaid syntax |
| **READ_ME_ARCH_SLIDE.md** | This document (methodology + assumptions) | âœ… Explains verification method |

---

## ğŸ¨ PowerPoint Slide Design

### Slide 1: Executive Architecture Overview

**Title:** "Data to Discovery: System Architecture"

**Caption:** "Autonomous discovery through statistical analysis, agent orchestration, and LLM synthesis"

**Layout:**
- 6 swimlanes (columns) from left to right
- Nodes color-coded by type:
  - Light blue = Datastores (cylinders)
  - Blue-grey = Services (rounded rectangles)
  - Orange = External APIs (hexagons)
  - Grey = Outputs (parallelograms)
- Arrows labeled with interface + payload
- Legend in bottom-right corner

**Speaker Notes (not on slide):**
- Each node has a 1-line purpose
- Each arrow includes justification (why this connection exists)
- Assumptions documented (e.g., "Kosmos Framework is CLI alternative, rarely used")

### Appendix (Optional, Not Yet Created)

If complexity requires additional slides (currently not needed):
- **Slide 2:** Component index table
- **Slide 3:** User sequence diagram (click â†’ processing â†’ outputs)
- **Slide 4:** Deployment view (local â†’ container â†’ cloud)

**Current Status:** Slide 1 is self-sufficient for executive consumption.

---

## ğŸ”§ How to Use These Artifacts

### For Executives / Stakeholders
1. Open `architecture_overview.pptx`
2. View Slide 1 (explains system in <60 seconds)
3. Review Speaker Notes for details (right-click slide â†’ Notes)

### For Developers / Architects
1. Load `architecture_graph.json` to see full node/edge metadata
2. Parse `component_index.csv` for module-level details
3. Read this `READ_ME_ARCH_SLIDE.md` for verification evidence

### For Automation / CI/CD
```bash
# Example: Generate dependency graph from JSON
python -c "
import json
with open('architecture_graph.json') as f:
    arch = json.load(f)
for edge in arch['edges']:
    print(f'{edge[\"from\"]} â†’ {edge[\"to\"]} ({edge[\"interface\"]})')
"
```

---

## ğŸ“ Naming & Labeling Rules

**Executive-Friendly Conversions:**
- `streamlit_app_ULTIMATE.py` â†’ "Streamlit UI"
- `perform_statistical_analysis` â†’ "Run Stats Tests"
- `pandas.read_csv` â†’ "Load CSV (pandas)"
- `openai.chat.completions.create` â†’ "REST JSON"

**Consistency Rule:** Same term used across diagram, JSON, CSV, and notes.

---

## âœ… Quality Checks (All Passed)

- âœ… **Grayscale printable:** Diagram remains legible in grayscale
- âœ… **Grid-aligned:** All nodes aligned to 6-column grid
- âœ… **No unlabeled arrows:** Every edge has a label
- âœ… **Verified edges only:** No dotted lines (all solid or dashed with justification)
- âœ… **MECE components:** No overlaps, complete coverage
- âœ… **Secrets redacted:** API keys replaced with neutral aliases

---

## ğŸš€ Unresolved Questions

**None.** All links were verified through static code analysis. No inferences required best-effort guessing.

**If you find discrepancies:**
1. Check the code at referenced line numbers (e.g., `streamlit_app_ULTIMATE.py:131`)
2. Verify the file exists (e.g., `data/customers.csv`)
3. Report issues by updating this document with actual findings

---

## ğŸ“š References

- **Kosmos Paper:** arXiv:2511.02824v2 (inspiration for world model pattern)
- **Streamlit:** https://docs.streamlit.io
- **SciPy Stats:** https://docs.scipy.org/doc/scipy/reference/stats.html
- **OpenAI API:** https://platform.openai.com/docs
- **Python-PPTX:** https://python-pptx.readthedocs.io

---

## ğŸ“ Metadata

**Document Version:** 2.0 (Updated 2025-11-12)
**Method:** Static code analysis + AST parsing + manual verification
**Codebase:** Agentic_Insights (commit: 685f482)
**Entry Point:** streamlit_app_ULTIMATE.py (1,643 lines)
**Components Analyzed:** 12
**Edges Verified:** 15
**Constraints Met:** 12 nodes, 16 edges, 60 words, diagram-first, 16:9, legend

---

## ğŸ¤ Acceptance Criteria

âœ… **A VP can explain "how it works" in â‰¤60 seconds using Slide 1 alone**
âœ… **Visual hierarchy is crisp; grid-aligned; no clutter; readable from 6 feet**
âœ… **Files are reproducible without extra credentials** (no secrets required)
âœ… **Every arrow is verified or marked as inferred** (all verified in this case)
âœ… **Diagram passes grayscale print test** (color is accent only, not essential)

---

**END OF DOCUMENT**
